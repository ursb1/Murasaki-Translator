# å¹³å°å…¼å®¹æ€§ä¸å®‰è£…æŒ‡å—

æœ¬æ–‡æ¡£è¯¦ç»†è¯´æ˜ Murasaki Translator åœ¨ä¸åŒå¹³å°ä¸Šçš„ä¸‹è½½ä¸è¿è¡Œæ­¥éª¤ã€‚

---

## ä¸‹è½½åŒ…ä¸€è§ˆ

| æ–‡ä»¶å | å¹³å° | GPU | è¯´æ˜ |
|--------|------|-----|------|
| `*-win-cuda-x64.zip` | Windows | NVIDIA | âœ… ä¸€é”®è¿è¡Œï¼Œè§£å‹å³ç”¨ |
| `*-win-vulkan-x64.zip` | Windows | AMD / Intel | âœ… ä¸€é”®è¿è¡Œï¼Œè§£å‹å³ç”¨ |
| `*-arm64.dmg` | macOS | Apple Silicon (M1/M2/M3/M4) | âœ… ä¸€é”®è¿è¡Œï¼ŒMetal åŠ é€Ÿ |
| `*.dmg` (æ—  arm64 åç¼€) | macOS | Intel | âœ… ä¸€é”®è¿è¡Œï¼ŒCPU æ¨¡å¼ |
| `*.AppImage` | Linux | æ‰€æœ‰ GPU (Vulkan) | âœ… ä¸€é”®è¿è¡Œï¼Œæ¡Œé¢ç”¨æˆ· |
| `murasaki-server-*.tar.gz` | Linux | æ‰€æœ‰ GPU | âš ï¸ CLI æœåŠ¡å™¨ï¼Œéœ€å®‰è£…ä¾èµ– |

---

## ğŸªŸ Windows

> [!IMPORTANT]
> **NVIDIA ç”¨æˆ·é©±åŠ¨è¦æ±‚**ï¼šé©±åŠ¨ç‰ˆæœ¬ â‰¥ 551.61ï¼ˆæ”¯æŒ CUDA 12.4+ï¼‰ã€‚æ— éœ€å®‰è£… CUDA Toolkitã€‚

### ä¸‹è½½ä¸è¿è¡Œ

1. **NVIDIA æ˜¾å¡**ï¼šä¸‹è½½ `Murasaki-Translator-*-win-cuda-x64.zip`
2. **AMD / Intel æ˜¾å¡**ï¼šä¸‹è½½ `Murasaki-Translator-*-win-vulkan-x64.zip`
3. è§£å‹åè¿è¡Œ `Murasaki Translator.exe`

ç¨‹åºä¼šè‡ªåŠ¨æ£€æµ‹ GPU å¹¶åŠ è½½å¯¹åº”åç«¯ã€‚

---

## ğŸ macOS

### ä¸‹è½½ä¸è¿è¡Œ

1. **Apple Silicon (M1/M2/M3/M4)**ï¼šä¸‹è½½ `Murasaki.Translator-*-arm64.dmg`
2. **Intel Mac**ï¼šä¸‹è½½ `Murasaki.Translator-*.dmg`ï¼ˆæ—  arm64 åç¼€ï¼‰
3. æ‰“å¼€ `.dmg`ï¼Œå°†åº”ç”¨æ‹–å…¥ Applications æ–‡ä»¶å¤¹
4. é¦–æ¬¡è¿è¡Œï¼šå³é”®ç‚¹å‡»åº”ç”¨ â†’ "æ‰“å¼€"ï¼ˆç»•è¿‡ Gatekeeperï¼‰

> Apple Silicon ä½¿ç”¨ Metal åŠ é€Ÿï¼Œæ€§èƒ½æ˜¾è‘—ä¼˜äº Intel Mac çš„ CPU æ¨¡å¼ã€‚

---

## ğŸ§ Linux

### æ¡Œé¢ç”¨æˆ·ï¼ˆAppImageï¼‰

ä¸‹è½½ `Murasaki-Translator-*.AppImage`ï¼Œæ·»åŠ æ‰§è¡Œæƒé™åè¿è¡Œï¼š

```bash
chmod +x Murasaki-Translator-*.AppImage
./Murasaki-Translator-*.AppImage
```

> AppImage å†…ç½® Vulkan åç«¯ï¼Œæ”¯æŒ NVIDIA / AMD / Intel æ˜¾å¡ã€‚

---

### æœåŠ¡å™¨ç”¨æˆ·ï¼ˆCLI Serverï¼‰

CLI æœåŠ¡å™¨æä¾› OpenAI å…¼å®¹ APIï¼Œé€‚åˆæœåŠ¡å™¨è¿è¡Œè½¬å‘ç»™å…¶ä»–ç»ˆç«¯æ‰¹é‡å¤„ç†ã€‚

#### éƒ¨ç½²æ­¥éª¤

```bash
# 1. ä¸‹è½½å¹¶è§£å‹
tar -xzf murasaki-server-linux-x64.tar.gz
cd murasaki-server

# 2. å®‰è£… Python ä¾èµ–
pip3 install -r requirements.txt
pip3 install fastapi uvicorn httpx

# 3. å¯åŠ¨æœåŠ¡
./start.sh --model /path/to/model.gguf --port 8000
```

#### GPU åç«¯è¯´æ˜

| ä½ çš„ç¡¬ä»¶ | è‡ªåŠ¨ä½¿ç”¨åç«¯ | å¤‡æ³¨ |
|----------|--------------|------|
| æ—  GPU / CPU æœåŠ¡å™¨ | `linux-cpu` | å¼€ç®±å³ç”¨ |
| AMD / Intel GPU | `linux-vulkan` | å¼€ç®±å³ç”¨ |
| NVIDIA GPU | `linux-vulkan` | é»˜è®¤å›é€€ï¼Œæ€§èƒ½æ¥è¿‘ CUDA |
| NVIDIA GPU + CUDA | `linux-cuda` | éœ€è‡ªè¡Œç¼–è¯‘ï¼Œè§ä¸‹æ–¹ |

---

### ğŸï¸ NVIDIA CUDA åŠ é€Ÿï¼ˆå¯é€‰ï¼‰

> llama.cpp å®˜æ–¹ä¸æä¾› Linux CUDA é¢„ç¼–è¯‘åŒ…ã€‚Vulkan åœ¨ NVIDIA ä¸Šæ€§èƒ½å·²æ¥è¿‘ CUDAï¼Œå¤§å¤šæ•°ç”¨æˆ·æ— éœ€ç¼–è¯‘ã€‚

å¦‚ç¡®éœ€ CUDA åŠ é€Ÿï¼š

```bash
# å‰ç½®æ¡ä»¶ï¼šå·²å®‰è£… CUDA Toolkit 12.x (éªŒè¯: nvcc --version)

git clone https://github.com/ggml-org/llama.cpp
cd llama.cpp
cmake -B build -DGGML_CUDA=ON
cmake --build build --config Release -j$(nproc)

# å¤åˆ¶åˆ° Murasaki ç›®å½•
mkdir -p /path/to/murasaki-server/bin/linux-cuda
cp build/bin/llama-server /path/to/murasaki-server/bin/linux-cuda/
chmod +x /path/to/murasaki-server/bin/linux-cuda/llama-server
```

ç¼–è¯‘å®Œæˆåï¼Œç¨‹åºä¼šè‡ªåŠ¨ä¼˜å…ˆä½¿ç”¨ `linux-cuda` åç«¯ã€‚

---

## ğŸ”§ å¸¸è§é—®é¢˜

| é—®é¢˜ | è§£å†³æ–¹æ¡ˆ |
|------|----------|
| macOS æç¤º"æ— æ³•éªŒè¯å¼€å‘è€…" | å³é”®åº”ç”¨ â†’ "æ‰“å¼€" |
| Linux AppImage æ— æ³•å¯åŠ¨ | å®‰è£… FUSEï¼š`sudo apt install libfuse2` |
| CLI æ‰¾ä¸åˆ° llama-server | æ£€æŸ¥ `bin/linux-vulkan/llama-server` æ˜¯å¦å­˜åœ¨ä¸”æœ‰æ‰§è¡Œæƒé™ |
